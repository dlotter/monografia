{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse jupyter notebook serve para transformar os dados brutos zipados em arquivos agregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diego/Desktop/monografia\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolsa Família"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de 2020-01 até 2021-10\n",
    "\n",
    "file_paths_bf = [    \n",
    "    'raw_data/bolsa_familia/files/201908',\n",
    "    'raw_data/bolsa_familia/files/201909',\n",
    "    'raw_data/bolsa_familia/files/201910',\n",
    "    'raw_data/bolsa_familia/files/201911',\n",
    "    'raw_data/bolsa_familia/files/201912',\n",
    "    'raw_data/bolsa_familia/files/202001',\n",
    "    'raw_data/bolsa_familia/files/202002',\n",
    "    'raw_data/bolsa_familia/files/202003',\n",
    "    'raw_data/bolsa_familia/files/202004',\n",
    "    'raw_data/bolsa_familia/files/202005',\n",
    "    'raw_data/bolsa_familia/files/202006',\n",
    "    'raw_data/bolsa_familia/files/202007',\n",
    "    'raw_data/bolsa_familia/files/202008',\n",
    "    'raw_data/bolsa_familia/files/202009',\n",
    "    'raw_data/bolsa_familia/files/202010',\n",
    "    'raw_data/bolsa_familia/files/202011',\n",
    "    'raw_data/bolsa_familia/files/202012',\n",
    "    'raw_data/bolsa_familia/files/202101',\n",
    "    'raw_data/bolsa_familia/files/202102',\n",
    "    'raw_data/bolsa_familia/files/202103',\n",
    "    'raw_data/bolsa_familia/files/202104',\n",
    "    'raw_data/bolsa_familia/files/202105',\n",
    "    'raw_data/bolsa_familia/files/202106',\n",
    "    'raw_data/bolsa_familia/files/202107',\n",
    "    'raw_data/bolsa_familia/files/202108',\n",
    "    'raw_data/bolsa_familia/files/202109',\n",
    "    'raw_data/bolsa_familia/files/202110',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_file_bf(path):\n",
    "    if os.path.exists(path):\n",
    "        with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('raw_data/bolsa_familia/files')\n",
    "    else:\n",
    "        print(f\"File {path} doesn't exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agg_chunks_bf(path_mes):\n",
    "    tamanho_total = 0\n",
    "    with pd.read_csv('raw_data/bolsa_familia/files/' + path_mes + '_BolsaFamilia_Pagamentos.csv', chunksize=500_000, sep=';', encoding='latin-1') as reader:\n",
    "            clean_chunks = []\n",
    "            for df in reader:\n",
    "                tamanho_total += len(df)\n",
    "                df['VALOR PARCELA'] = df['VALOR PARCELA'].str.replace(',','.')\n",
    "                df['VALOR PARCELA'] = df['VALOR PARCELA'].astype(float)\n",
    "\n",
    "                colunas = ['CÓDIGO MUNICÍPIO SIAFI', 'VALOR PARCELA', 'NOME FAVORECIDO']\n",
    "\n",
    "                valores_soma = df[colunas].groupby(['CÓDIGO MUNICÍPIO SIAFI'],dropna=False).sum(numeric_only=True).reset_index()\n",
    "                valores_count = df[colunas].groupby(['CÓDIGO MUNICÍPIO SIAFI', \"NOME FAVORECIDO\"],dropna=False).size().groupby(['CÓDIGO MUNICÍPIO SIAFI']).size().reset_index()\n",
    "\n",
    "                df_merge = valores_soma.merge(valores_count, on='CÓDIGO MUNICÍPIO SIAFI', how='outer')\n",
    "                df_merge.columns = ['municipio_siafi', 'soma', 'contagem']\n",
    "                clean_chunks.append(df_merge)\n",
    "    return clean_chunks, tamanho_total\n",
    "\n",
    "def merge_chunks_bf(clean_chunks):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for chunk in clean_chunks:\n",
    "        if df.empty:\n",
    "            df = chunk\n",
    "        else:\n",
    "            df_merge = df.merge(chunk, on='municipio_siafi', how='outer')\n",
    "            assert len(df_merge) <= len(df) + len(chunk)\n",
    "            df_merge = df_merge.fillna(0)\n",
    "            df_merge['contagem'] = df_merge['contagem_x'] + df_merge['contagem_y']\n",
    "            df_merge['soma'] = df_merge['soma_x'] + df_merge['soma_y']\n",
    "            df_merge = df_merge.drop(['soma_x', 'soma_y', 'contagem_x', 'contagem_y'], axis=1)\n",
    "            df = df_merge\n",
    "    return df\n",
    "\n",
    "def transform_file_bf(path):\n",
    "    path_mes = path.split('/')[-1]\n",
    "\n",
    "    # Check if transformed file already exists\n",
    "    file_destination_name = 'parsed_data/bolsa_familia/files/' + path_mes + '.csv'\n",
    "\n",
    "    if os.path.exists(file_destination_name):\n",
    "        print(f'Arquivo {file_destination_name} já existente, pulando transformação.')\n",
    "        return\n",
    "    \n",
    "    # Check if extracted file already exists\n",
    "    extracted_file = 'raw_data/bolsa_familia/files/' + path_mes + '_BolsaFamilia_Pagamentos.csv'\n",
    "    if not os.path.exists(extracted_file):\n",
    "        print(f'Extraindo {path}.')\n",
    "        extract_zip_file_bf(path)\n",
    "        print(f'Concluído.')\n",
    "    else:  \n",
    "        print(f'Dados já extraídos, reaproveitando {extracted_file}.')\n",
    "    \n",
    "    print(f'Agregando dados.')\n",
    "\n",
    "    clean_chunks, tamanho_total = create_agg_chunks_bf(path_mes)\n",
    "\n",
    "    print(f'tamanho total: {tamanho_total}')\n",
    "\n",
    "    df_final = merge_chunks_bf(clean_chunks)\n",
    "\n",
    "    print(f'Concluído.')\n",
    "    df_final.to_csv(file_destination_name, index=False)\n",
    "    print(f'Arquivo salvo em {file_destination_name}.')\n",
    "\n",
    "    # Clean extracted file in the end\n",
    "    print(f'Apagando csv extraído.')\n",
    "    os.remove(extracted_file)\n",
    "    print(f'Concluído.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo parsed_data/bolsa_familia/201908.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/201909.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/201910.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/201911.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/201912.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202001.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202002.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202003.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202004.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202005.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202006.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202007.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202008.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202009.csv já existente, pulando transformação.\n",
      "Arquivo parsed_data/bolsa_familia/202010.csv já existente, pulando transformação.\n",
      "Extraindo raw_data/bolsa_familia/202011.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14273799\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202011.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202012.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14274019\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202012.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202101.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14233117\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202101.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202102.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14266042\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202102.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202103.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14524589\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202103.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202104.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14613280\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202104.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202105.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14695132\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202105.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202106.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14694799\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202106.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202107.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14694737\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202107.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202108.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14655448\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202108.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202109.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14655291\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202109.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Extraindo raw_data/bolsa_familia/202110.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "tamanho total: 14654789\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/bolsa_familia/202110.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n"
     ]
    }
   ],
   "source": [
    "for file in file_paths_bf:\n",
    "    transform_file_bf(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxílio Emergencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de 2020-01 até 2021-10\n",
    "\n",
    "file_paths_ae = [    \n",
    "    'raw_data/auxilio_emergencial/files/202206',\n",
    "    'raw_data/auxilio_emergencial/files/202205',\n",
    "    'raw_data/auxilio_emergencial/files/202204',\n",
    "    'raw_data/auxilio_emergencial/files/202203',\n",
    "    'raw_data/auxilio_emergencial/files/202202',\n",
    "    'raw_data/auxilio_emergencial/files/202201',\n",
    "    'raw_data/auxilio_emergencial/files/202112',\n",
    "    'raw_data/auxilio_emergencial/files/202111',\n",
    "    'raw_data/auxilio_emergencial/files/202110',\n",
    "    'raw_data/auxilio_emergencial/files/202109',\n",
    "    'raw_data/auxilio_emergencial/files/202108',\n",
    "    'raw_data/auxilio_emergencial/files/202107',\n",
    "    'raw_data/auxilio_emergencial/files/202106',\n",
    "    'raw_data/auxilio_emergencial/files/202105',\n",
    "    'raw_data/auxilio_emergencial/files/202104',\n",
    "    'raw_data/auxilio_emergencial/files/202103',\n",
    "    'raw_data/auxilio_emergencial/files/202102',\n",
    "    'raw_data/auxilio_emergencial/files/202101',\n",
    "    'raw_data/auxilio_emergencial/files/202012',\n",
    "    'raw_data/auxilio_emergencial/files/202011',\n",
    "    'raw_data/auxilio_emergencial/files/202010',\n",
    "    'raw_data/auxilio_emergencial/files/202009',\n",
    "    'raw_data/auxilio_emergencial/files/202008',\n",
    "    'raw_data/auxilio_emergencial/files/202007',\n",
    "    'raw_data/auxilio_emergencial/files/202006',\n",
    "    'raw_data/auxilio_emergencial/files/202005',\n",
    "    'raw_data/auxilio_emergencial/files/202004',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_file_ae(path):\n",
    "    if os.path.exists(path):\n",
    "        with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall('raw_data/auxilio_emergencial/files/')\n",
    "    else:\n",
    "        print(f\"File {path} doesn't exist.\")\n",
    "\n",
    "def create_agg_chunks_ae(path_mes):\n",
    "    tamanho_total = 0\n",
    "    with pd.read_csv('raw_data/auxilio_emergencial/files/' + path_mes + '_AuxilioEmergencial.csv', chunksize=500_000, sep=';', encoding='latin-1') as reader:\n",
    "            clean_chunks = []\n",
    "            for df in reader:\n",
    "                df['VALOR BENEFÍCIO'] = df['VALOR BENEFÍCIO'].str.replace(',','.')\n",
    "                df['VALOR BENEFÍCIO'] = df['VALOR BENEFÍCIO'].astype(float)\n",
    "\n",
    "                obs_filter = (df['OBSERVAÇÃO'] == 'Não há') | (df['OBSERVAÇÃO'].isna())\n",
    "\n",
    "                df = df[obs_filter]\n",
    "                \n",
    "                tamanho_total += len(df)\n",
    "\n",
    "                colunas = ['CÓDIGO MUNICÍPIO IBGE', 'VALOR BENEFÍCIO', 'NOME BENEFICIÁRIO']\n",
    "\n",
    "                valores_soma = df[colunas].groupby(['CÓDIGO MUNICÍPIO IBGE'],dropna=False).sum().reset_index()\n",
    "                valores_count = df[colunas].groupby(['CÓDIGO MUNICÍPIO IBGE', 'NOME BENEFICIÁRIO'], dropna=False).size().groupby(['CÓDIGO MUNICÍPIO IBGE']).size().reset_index()\n",
    "\n",
    "                df_merge = valores_soma.merge(valores_count, on='CÓDIGO MUNICÍPIO IBGE', how='outer')\n",
    "                df_merge.columns = ['municipio_ibge', 'soma', 'contagem']\n",
    "                clean_chunks.append(df_merge)\n",
    "    return clean_chunks, tamanho_total\n",
    "\n",
    "def merge_chunks_ae(clean_chunks):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for chunk in clean_chunks:\n",
    "        if df.empty:\n",
    "            df = chunk\n",
    "        else:\n",
    "            df_merge = df.merge(chunk, on='municipio_ibge', how='outer')\n",
    "            assert len(df_merge) <= len(df) + len(chunk)\n",
    "            df_merge = df_merge.fillna(0)\n",
    "            df_merge['contagem'] = df_merge['contagem_x'] + df_merge['contagem_y']\n",
    "            df_merge['soma'] = df_merge['soma_x'] + df_merge['soma_y']\n",
    "            df_merge = df_merge.drop(['soma_x', 'soma_y', 'contagem_x', 'contagem_y'], axis=1)\n",
    "            df = df_merge\n",
    "    return df\n",
    "\n",
    "def transform_file_ae(path):\n",
    "    path_mes = path.split('/')[-1]\n",
    "\n",
    "    # Check if transformed file already exists\n",
    "    file_destination_name = 'parsed_data/auxilio_emergencial/files/' + path_mes + '.csv'\n",
    "\n",
    "    if os.path.exists(file_destination_name):\n",
    "        print(f'Arquivo {file_destination_name} já existente, pulando.. transformação.')\n",
    "        return\n",
    "    \n",
    "    # Check if extracted file already exists\n",
    "    extracted_file = 'raw_data/auxilio_emergencial/files/' + path_mes + '_AuxilioEmergencial.csv'\n",
    "    if not os.path.exists(extracted_file):\n",
    "        print(f'Extraindo {path}.')\n",
    "        extract_zip_file_ae(path)\n",
    "        print(f'Concluído.')\n",
    "    else:  \n",
    "        print(f'Dados já extraídos, reaproveitando {extracted_file}.')\n",
    "    \n",
    "    print(f'Agregando dados.')\n",
    "\n",
    "    clean_chunks, tamanho_total = create_agg_chunks_ae(path_mes)\n",
    "\n",
    "    print(f'tamanho total: {tamanho_total}')\n",
    "\n",
    "    df_final = merge_chunks_ae(clean_chunks)\n",
    "\n",
    "    print(f'Concluído.')\n",
    "    df_final.to_csv(file_destination_name, index=False)\n",
    "    print(f'Arquivo salvo em {file_destination_name}.')\n",
    "\n",
    "    # Clean extracted file in the end\n",
    "    print(f'Apagando csv extraído.')\n",
    "    os.remove(extracted_file)\n",
    "    print(f'Concluído.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo raw_data/auxilio_emergencial/files/202206.\n",
      "Concluído.\n",
      "Agregando dados.\n",
      "Help on int64 object:\n",
      "\n",
      "class int64(signedinteger)\n",
      " |  Signed integer type, compatible with Python `int` and C ``long``.\n",
      " |  \n",
      " |  :Character code: ``'l'``\n",
      " |  :Canonical name: `numpy.int_`\n",
      " |  :Alias on this platform (Linux x86_64): `numpy.int64`: 64-bit signed integer (``-9_223_372_036_854_775_808`` to ``9_223_372_036_854_775_807``).\n",
      " |  :Alias on this platform (Linux x86_64): `numpy.intp`: Signed integer large enough to fit pointer, compatible with C ``intptr_t``.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      int64\n",
      " |      signedinteger\n",
      " |      integer\n",
      " |      number\n",
      " |      generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __abs__(self, /)\n",
      " |      abs(self)\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __and__(self, value, /)\n",
      " |      Return self&value.\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      self != 0\n",
      " |  \n",
      " |  __divmod__(self, value, /)\n",
      " |      Return divmod(self, value).\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __float__(self, /)\n",
      " |      float(self)\n",
      " |  \n",
      " |  __floordiv__(self, value, /)\n",
      " |      Return self//value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __index__(self, /)\n",
      " |      Return self converted to an integer, if self is suitable for use as an index into a list.\n",
      " |  \n",
      " |  __int__(self, /)\n",
      " |      int(self)\n",
      " |  \n",
      " |  __invert__(self, /)\n",
      " |      ~self\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lshift__(self, value, /)\n",
      " |      Return self<<value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __neg__(self, /)\n",
      " |      -self\n",
      " |  \n",
      " |  __or__(self, value, /)\n",
      " |      Return self|value.\n",
      " |  \n",
      " |  __pos__(self, /)\n",
      " |      +self\n",
      " |  \n",
      " |  __pow__(self, value, mod=None, /)\n",
      " |      Return pow(self, value, mod).\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __rand__(self, value, /)\n",
      " |      Return value&self.\n",
      " |  \n",
      " |  __rdivmod__(self, value, /)\n",
      " |      Return divmod(value, self).\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rfloordiv__(self, value, /)\n",
      " |      Return value//self.\n",
      " |  \n",
      " |  __rlshift__(self, value, /)\n",
      " |      Return value<<self.\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __ror__(self, value, /)\n",
      " |      Return value|self.\n",
      " |  \n",
      " |  __rpow__(self, value, mod=None, /)\n",
      " |      Return pow(value, self, mod).\n",
      " |  \n",
      " |  __rrshift__(self, value, /)\n",
      " |      Return value>>self.\n",
      " |  \n",
      " |  __rshift__(self, value, /)\n",
      " |      Return self>>value.\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __rtruediv__(self, value, /)\n",
      " |      Return value/self.\n",
      " |  \n",
      " |  __rxor__(self, value, /)\n",
      " |      Return value^self.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  __truediv__(self, value, /)\n",
      " |      Return self/value.\n",
      " |  \n",
      " |  __xor__(self, value, /)\n",
      " |      Return self^value.\n",
      " |  \n",
      " |  bit_count(...)\n",
      " |      int64.bit_count() -> int\n",
      " |      \n",
      " |      Computes the number of 1-bits in the absolute value of the input.\n",
      " |      Analogous to the builtin `int.bit_count` or ``popcount`` in C++.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.int64(127).bit_count()\n",
      " |      7\n",
      " |      >>> np.int64(-127).bit_count()\n",
      " |      7\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  __class_getitem__(...) from builtins.type\n",
      " |      __class_getitem__(item, /)\n",
      " |      \n",
      " |      Return a parametrized wrapper around the `~numpy.number` type.\n",
      " |      \n",
      " |      .. versionadded:: 1.22\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      alias : types.GenericAlias\n",
      " |          A parametrized `~numpy.number` type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from typing import Any\n",
      " |      >>> import numpy as np\n",
      " |      \n",
      " |      >>> np.signedinteger[Any]\n",
      " |      numpy.signedinteger[typing.Any]\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is only available for python 3.9 and later.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :pep:`585` : Type hinting generics in standard collections.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from integer:\n",
      " |  \n",
      " |  __round__(...)\n",
      " |  \n",
      " |  is_integer(...)\n",
      " |      integer.is_integer() -> bool\n",
      " |      \n",
      " |      Return ``True`` if the number is finite with integral value.\n",
      " |      \n",
      " |      .. versionadded:: 1.22\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.int64(-2).is_integer()\n",
      " |      True\n",
      " |      >>> np.uint32(5).is_integer()\n",
      " |      True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from integer:\n",
      " |  \n",
      " |  denominator\n",
      " |      denominator of value (1)\n",
      " |  \n",
      " |  numerator\n",
      " |      numerator of value (the value itself)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from generic:\n",
      " |  \n",
      " |  __array__(...)\n",
      " |      sc.__array__(dtype) return 0-dim array from scalar with specified dtype\n",
      " |  \n",
      " |  __array_wrap__(...)\n",
      " |      sc.__array_wrap__(obj) return scalar from array\n",
      " |  \n",
      " |  __copy__(...)\n",
      " |  \n",
      " |  __deepcopy__(...)\n",
      " |  \n",
      " |  __format__(...)\n",
      " |      NumPy array scalar formatter\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      Size of object in memory, in bytes.\n",
      " |  \n",
      " |  all(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.all`.\n",
      " |  \n",
      " |  any(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.any`.\n",
      " |  \n",
      " |  argmax(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.argmax`.\n",
      " |  \n",
      " |  argmin(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.argmin`.\n",
      " |  \n",
      " |  argsort(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.argsort`.\n",
      " |  \n",
      " |  astype(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.astype`.\n",
      " |  \n",
      " |  byteswap(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.byteswap`.\n",
      " |  \n",
      " |  choose(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.choose`.\n",
      " |  \n",
      " |  clip(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.clip`.\n",
      " |  \n",
      " |  compress(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.compress`.\n",
      " |  \n",
      " |  conj(...)\n",
      " |  \n",
      " |  conjugate(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.conjugate`.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.copy`.\n",
      " |  \n",
      " |  cumprod(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.cumprod`.\n",
      " |  \n",
      " |  cumsum(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.cumsum`.\n",
      " |  \n",
      " |  diagonal(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.diagonal`.\n",
      " |  \n",
      " |  dump(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.dump`.\n",
      " |  \n",
      " |  dumps(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.dumps`.\n",
      " |  \n",
      " |  fill(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.fill`.\n",
      " |  \n",
      " |  flatten(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.flatten`.\n",
      " |  \n",
      " |  getfield(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.getfield`.\n",
      " |  \n",
      " |  item(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.item`.\n",
      " |  \n",
      " |  itemset(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.itemset`.\n",
      " |  \n",
      " |  max(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.max`.\n",
      " |  \n",
      " |  mean(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.mean`.\n",
      " |  \n",
      " |  min(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.min`.\n",
      " |  \n",
      " |  newbyteorder(...)\n",
      " |      newbyteorder(new_order='S', /)\n",
      " |      \n",
      " |      Return a new `dtype` with a different byte order.\n",
      " |      \n",
      " |      Changes are also made in all fields and sub-arrays of the data type.\n",
      " |      \n",
      " |      The `new_order` code can be any from the following:\n",
      " |      \n",
      " |      * 'S' - swap dtype from current to opposite endian\n",
      " |      * {'<', 'little'} - little endian\n",
      " |      * {'>', 'big'} - big endian\n",
      " |      * {'=', 'native'} - native order\n",
      " |      * {'|', 'I'} - ignore (no change to byte order)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_order : str, optional\n",
      " |          Byte order to force; a value from the byte order specifications\n",
      " |          above.  The default value ('S') results in swapping the current\n",
      " |          byte order.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_dtype : dtype\n",
      " |          New `dtype` object with the given change to the byte order.\n",
      " |  \n",
      " |  nonzero(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.nonzero`.\n",
      " |  \n",
      " |  prod(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.prod`.\n",
      " |  \n",
      " |  ptp(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.ptp`.\n",
      " |  \n",
      " |  put(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.put`.\n",
      " |  \n",
      " |  ravel(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.ravel`.\n",
      " |  \n",
      " |  repeat(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.repeat`.\n",
      " |  \n",
      " |  reshape(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.reshape`.\n",
      " |  \n",
      " |  resize(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.resize`.\n",
      " |  \n",
      " |  round(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.round`.\n",
      " |  \n",
      " |  searchsorted(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.searchsorted`.\n",
      " |  \n",
      " |  setfield(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.setfield`.\n",
      " |  \n",
      " |  setflags(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.setflags`.\n",
      " |  \n",
      " |  sort(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.sort`.\n",
      " |  \n",
      " |  squeeze(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.squeeze`.\n",
      " |  \n",
      " |  std(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.std`.\n",
      " |  \n",
      " |  sum(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.sum`.\n",
      " |  \n",
      " |  swapaxes(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.swapaxes`.\n",
      " |  \n",
      " |  take(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.take`.\n",
      " |  \n",
      " |  tobytes(...)\n",
      " |  \n",
      " |  tofile(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.tofile`.\n",
      " |  \n",
      " |  tolist(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.tolist`.\n",
      " |  \n",
      " |  tostring(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.tostring`.\n",
      " |  \n",
      " |  trace(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.trace`.\n",
      " |  \n",
      " |  transpose(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.transpose`.\n",
      " |  \n",
      " |  var(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.var`.\n",
      " |  \n",
      " |  view(...)\n",
      " |      Scalar method identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.view`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from generic:\n",
      " |  \n",
      " |  T\n",
      " |      Scalar attribute identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.T`.\n",
      " |  \n",
      " |  __array_interface__\n",
      " |      Array protocol: Python side\n",
      " |  \n",
      " |  __array_priority__\n",
      " |      Array priority.\n",
      " |  \n",
      " |  __array_struct__\n",
      " |      Array protocol: struct\n",
      " |  \n",
      " |  base\n",
      " |      Scalar attribute identical to the corresponding array attribute.\n",
      " |      \n",
      " |      Please see `ndarray.base`.\n",
      " |  \n",
      " |  data\n",
      " |      Pointer to start of data.\n",
      " |  \n",
      " |  dtype\n",
      " |      Get array data-descriptor.\n",
      " |  \n",
      " |  flags\n",
      " |      The integer value of flags.\n",
      " |  \n",
      " |  flat\n",
      " |      A 1-D view of the scalar.\n",
      " |  \n",
      " |  imag\n",
      " |      The imaginary part of the scalar.\n",
      " |  \n",
      " |  itemsize\n",
      " |      The length of one element in bytes.\n",
      " |  \n",
      " |  nbytes\n",
      " |      The length of the scalar in bytes.\n",
      " |  \n",
      " |  ndim\n",
      " |      The number of array dimensions.\n",
      " |  \n",
      " |  real\n",
      " |      The real part of the scalar.\n",
      " |  \n",
      " |  shape\n",
      " |      Tuple of array dimensions.\n",
      " |  \n",
      " |  size\n",
      " |      The number of elements in the gentype.\n",
      " |  \n",
      " |  strides\n",
      " |      Tuple of bytes steps in each dimension.\n",
      "\n",
      "tamanho total: 7167\n",
      "Concluído.\n",
      "Arquivo salvo em parsed_data/auxilio_emergencial/files/202206.csv.\n",
      "Apagando csv extraído.\n",
      "Concluído.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202205.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202204.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202203.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202202.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202201.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202112.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202111.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202110.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202109.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202108.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202107.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202106.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202105.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202104.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202103.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202102.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202101.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202012.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202011.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202010.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202009.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202008.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202007.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202006.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202005.csv já existente, pulando.. transformação.\n",
      "Arquivo parsed_data/auxilio_emergencial/files/202004.csv já existente, pulando.. transformação.\n"
     ]
    }
   ],
   "source": [
    "for file in file_paths_ae:\n",
    "    transform_file_ae(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a648c56f55f8b0168fc47465c367b5026ef090b20d6c3f78c4f8ca7d1e2574c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
